inputs:
  question:
    type: string
    default: Show me top 3 CDO candidates with details?
    is_chat_input: false
outputs:
  output:
    type: string
    reference: ${answer_the_question_with_context.output}
    evaluation_only: false
    is_chat_output: false
nodes:
- name: embed_the_question
  type: python
  source:
    type: package
    tool: promptflow.tools.embedding.embedding
  inputs:
    connection: aoainclat
    deployment_name: text-embedding-ada-002
    input: ${flow.question}
  aggregation: false
  use_variants: false
- name: search_question_from_indexed_docs
  type: python
  source:
    type: package
    tool: promptflow_vectordb.tool.vector_index_lookup.VectorIndexLookup.search
  inputs:
    path: azureml://subscriptions/80ef7369-572a-4abd-b09a-033367f44858/resourcegroups/mlopsdeveast/providers/Microsoft.MachineLearningServices/workspaces/amleastus/data/profileindex3/versions/1
    query: ${embed_the_question.output}
    top_k: 10
  aggregation: false
  use_variants: false
- name: generate_prompt_context
  type: python
  source:
    type: code
    path: generate_prompt_context.py
  inputs:
    search_result: ${search_question_from_indexed_docs.output}
  aggregation: false
  use_variants: false
- name: Prompt_variants
  use_variants: true
- name: answer_the_question_with_context
  type: llm
  source:
    type: code
    path: answer_the_question_with_context.jinja2
  inputs:
    deployment_name: gpt-35-turbo-16k
    temperature: 0
    top_p: 1
    stop: ""
    max_tokens: 1000
    presence_penalty: 0
    frequency_penalty: 0
    logit_bias: ""
    prompt_text: ${Prompt_variants.output}
  provider: AzureOpenAI
  connection: aoainclat
  api: chat
  module: promptflow.tools.aoai
  aggregation: false
  use_variants: false
node_variants:
  Prompt_variants:
    default_variant_id: Variant_0
    variants:
      Variant_0:
        node:
          name: Prompt_variants
          type: prompt
          source:
            type: code
            path: Prompt_variants__Variant_0.jinja2
          inputs:
            contexts: ${generate_prompt_context.output}
            question: ${flow.question}
          aggregation: false
      Variant_1:
        node:
          name: Prompt_variants
          type: prompt
          source:
            type: code
            path: Prompt_variants__Variant_1.jinja2
          inputs:
            contexts: ${generate_prompt_context.output}
            question: ${flow.question}
          aggregation: false
      Variant_2:
        node:
          name: Prompt_variants
          type: prompt
          source:
            type: code
            path: Prompt_variants__Variant_2.jinja2
          inputs:
            contexts: ${generate_prompt_context.output}
            question: ${flow.question}
          aggregation: false
environment:
  python_requirements_txt: requirements.txt
